{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ed17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.patches import Ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af93f1a9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nuts = True\n",
    "sigma1, sigma2 = 1.0, 10.0\n",
    "beta = 1.0  # Inverse temperature\n",
    "steps = 2 ** 15\n",
    "n_bins = 8\n",
    "initial_sample = np.array([0.0, 0.0])\n",
    "step_size = 0.4\n",
    "Delta = 1000\n",
    "num_leapfrog_steps = 50  # If not nuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd87991d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def log_target_density(x, beta):\n",
    "    # Target density: a bivariate normal distribution.\n",
    "    E = (x[0] - x[1])**2 / (2*sigma1**2) + (x[0] + x[1])**2 / (2*sigma2**2)\n",
    "    return - beta * E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0e956",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def gradient_log_target_density(x, beta):\n",
    "    grad_x1 = (x[0] - x[1]) / (sigma1**2) + (x[0] + x[1]) / (sigma2**2)\n",
    "    grad_x2 = - (x[0] - x[1]) / (sigma1**2) + (x[0] + x[1]) / (sigma2**2)\n",
    "    return - np.array([grad_x1, grad_x2]) * beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253b2d4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def leapfrog(x, p, grad, beta, step_size, num_steps):\n",
    "    x_new = np.copy(x)\n",
    "    p_new = np.copy(p)\n",
    "    \n",
    "    p_new -= 0.5 * step_size * grad(x_new, beta)\n",
    "    for _ in range(num_steps - 1):\n",
    "        x_new += step_size * p_new\n",
    "        p_new -= step_size * grad(x_new, beta)\n",
    "    x_new += step_size * p_new\n",
    "    p_new -= 0.5 * step_size * grad(x_new, beta)\n",
    "    \n",
    "    return x_new, p_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677a5081",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def build_tree(x, p, u, v, j, dt, beta):\n",
    "    # Recursively doubling the size of a binary tree\n",
    "    if j == 0:\n",
    "        x2, p2 = leapfrog(x, p, grad=gradient_log_target_density, beta=beta, step_size=v*dt, num_steps=1)\n",
    "        H2 = -log_target_density(x2, beta) + 0.5 * np.sum(p2**2)\n",
    "        if np.log(u) <= - H2:\n",
    "            # Candidate\n",
    "            C2 = [x2.tolist()]\n",
    "        else:\n",
    "            C2 = []\n",
    "        \n",
    "        if np.log(u) > Delta - H2:            \n",
    "            # Too large energy\n",
    "            s2 = False\n",
    "        else:\n",
    "            s2 = True\n",
    "\n",
    "        return x2, p2, x2, p2, C2, s2\n",
    "    else:\n",
    "        xm, pm, xp, pp, C2, s2 = build_tree(x, p, u, v, j-1, dt, beta)\n",
    "        if v == -1:\n",
    "            xm, pm, _, _, C3, s3 = build_tree(xm, pm, u, v, j-1, dt, beta)\n",
    "        else:\n",
    "            _, _, xp, pp, C3, s3 = build_tree(xp, pp, u, v, j-1, dt, beta)\n",
    "\n",
    "        s_uturn = np.dot(xp - xm, pm) >= 0 and np.dot(xp - xm, pp) >= 0\n",
    "        s2 = s2 and s3 and s_uturn\n",
    "        C2 += C3        \n",
    "        return xm, pm, xp, pp, C2, s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5922410",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def HMC(target_log_density, gradient_log_density, beta, initial_sample, steps, step_size, num_leapfrog_steps, obs1, obs2, nuts=True):\n",
    "    samples = np.zeros((steps, 2))\n",
    "    samples[0] = initial_sample\n",
    "    burn_in = steps // 2\n",
    "    bin_size = max((steps - burn_in) // n_bins, 1)\n",
    "    o1 = 0\n",
    "    o2 = 0\n",
    "    n_samp = 0\n",
    "\n",
    "    for i in range(1, steps):\n",
    "        x0 = samples[i-1]\n",
    "        p0 = np.random.normal(size=2) # Initialize momentum\n",
    "        if nuts:\n",
    "            # No-U-turn sampler\n",
    "            H = -target_log_density(x0, beta) + 0.5 * np.sum(p0**2)\n",
    "            # Slice sampling\n",
    "            u = np.random.rand() * np.exp(-H)\n",
    "            xm, xp = x0, x0\n",
    "            pm, pp = p0, p0\n",
    "            j = 0\n",
    "            C = [x0.tolist()]            \n",
    "            s = True\n",
    "            while s:\n",
    "                v = np.random.choice([-1,1])\n",
    "                if v == -1:\n",
    "                    xm, pm, _, _, C2, s2 = build_tree(xm, pm, u, v, j, step_size, beta)\n",
    "                else:\n",
    "                    _, _, xp, pp, C2, s2 = build_tree(xp, pp, u, v, j, step_size, beta)\n",
    "                \n",
    "                if s2:\n",
    "                    C += C2\n",
    "                s_uturn = np.dot(xp - xm, pm) >= 0 and np.dot(xp - xm, pp) >= 0\n",
    "                s = s2 and s_uturn\n",
    "                j += 1\n",
    "\n",
    "            # Uniform random choice\n",
    "            samples[i] = random.choice(C)\n",
    "        else:\n",
    "            # Naive version\n",
    "            proposed_x, proposed_p = leapfrog(x=x0, p=p0, grad=gradient_log_density, beta=beta, step_size=step_size, num_steps=num_leapfrog_steps)\n",
    "        \n",
    "            # Compute Hamiltonian for the current and proposed state\n",
    "            current_H = -target_log_density(x0, beta) + 0.5 * np.sum(p0**2)\n",
    "            proposed_H = -target_log_density(proposed_x, beta) + 0.5 * np.sum(proposed_p**2)\n",
    "            \n",
    "            # Acceptance criterion\n",
    "            if np.random.rand() < np.exp((current_H - proposed_H)):\n",
    "                samples[i] = proposed_x\n",
    "            else:\n",
    "                samples[i] = x0\n",
    "\n",
    "        # Measurement\n",
    "        if i >= burn_in:        \n",
    "            _sum = sum(samples[i])\n",
    "            o1 += _sum\n",
    "            o2 += _sum ** 2\n",
    "            n_samp += 1\n",
    "            if n_samp == bin_size:\n",
    "                obs1.append(o1/bin_size)\n",
    "                obs2.append(o2/bin_size)\n",
    "                o1 = 0\n",
    "                o2 = 0\n",
    "                n_samp = 0\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd18ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample\n",
    "obs1, obs2 = [], []\n",
    "samples = HMC(log_target_density, gradient_log_target_density, beta, initial_sample, steps, step_size, num_leapfrog_steps, obs1, obs2, nuts=nuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fabaed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observables\n",
    "mu1, std1 = np.mean(obs1), np.std(obs1, ddof=1) / np.sqrt(len(obs1))\n",
    "mu2, std2 = np.mean(obs2), np.std(obs2, ddof=1) / np.sqrt(len(obs2))\n",
    "print(f'(x_1 + x_2): Sample mean: {mu1}, Sample standard deviation: {std1}')\n",
    "print(f'(x_1 + x_2)^2: Sample mean: {mu2}, Sample standard deviation: {std2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d06e65",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set up the figure for animation\n",
    "fig, ax = plt.subplots()\n",
    "xlim = 1.5 * sigma2\n",
    "ax.set_xlim([-xlim, xlim])\n",
    "ax.set_ylim([-xlim, xlim])\n",
    "ax.set_title('Hamiltonian Monte Carlo')\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "line, = ax.plot([], [], lw=1)\n",
    "scatter = ax.scatter([], [], s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a0216",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Initialization for the animation\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    scatter.set_offsets(np.empty((0, 2)))\n",
    "    return line, scatter,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380c80a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Update function for the animation that includes a line connecting the plots\n",
    "def update_line(i, samples, line, scatter):\n",
    "    line.set_data(samples[:i+1, 0], samples[:i+1, 1])\n",
    "    scatter.set_offsets(samples[:i+1])\n",
    "    return line, scatter,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5bd3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-sigma line\n",
    "ellipse = Ellipse(xy=(0, 0), width=2*np.sqrt(2)*sigma2, height=2*np.sqrt(2)*sigma1, angle=45, edgecolor='k', fc='None', lw=2)\n",
    "ax.add_patch(ellipse)\n",
    "# Setting the aspect ratio to 'equal' so the ellipse isn't distorted\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e38e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the plot\n",
    "plt.grid(True)\n",
    "# Create the animation\n",
    "ani = animation.FuncAnimation(fig, update_line, init_func=init, frames=steps, fargs=(samples, line, scatter), interval=20, blit=True)\n",
    "# ani.save('animation.gif', writer='imagemagick', fps=60)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
